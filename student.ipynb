{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing 1, 2, 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T16:44:47.051467Z",
     "start_time": "2021-12-02T16:44:47.047666Z"
    }
   },
   "source": [
    "# Phase 2 Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.457296Z",
     "start_time": "2021-12-17T18:37:26.380599Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.regression.linear_model import OLS\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.stats as stats\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "df = pd.read_csv('Data/kc_house_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.460005Z",
     "start_time": "2021-12-17T18:37:27.458349Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000) #change the amount of rows displayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-10T18:38:01.028331Z",
     "start_time": "2021-12-10T18:38:01.023789Z"
    }
   },
   "source": [
    "## Glossary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-02T17:31:03.783782Z",
     "start_time": "2021-12-02T17:31:03.758213Z"
    }
   },
   "source": [
    "### Column Names and descriptions for Kings County Data Set\n",
    "(source: Data/column_names.md)\n",
    "* **id** - unique identified for a house\n",
    "* **date** - house was sold\n",
    "* **price** -  is prediction target\n",
    "* **bedrooms** -  of Bedrooms/House\n",
    "* **bathrooms** -  of bathrooms/bedrooms\n",
    "* **sqft_livings** -  footage of the home\n",
    "* **sqft_lots** -  footage of the lot\n",
    "* **floors** -  floors (levels) in house\n",
    "* **waterfront** - House which has a view to a waterfront\n",
    "* **view** - Has been viewed\n",
    "* **condition** - How good the condition is ( Overall )\n",
    "* **grade** - overall grade given to the housing unit, based on King County grading system\n",
    "* **sqft_above** - square footage of house apart from basement\n",
    "* **sqft_basement** - square footage of the basement\n",
    "* **yr_built** - Built Year\n",
    "* **yr_renovated** - Year when house was renovated\n",
    "* **zipcode** - zip\n",
    "* **lat** - Latitude coordinate\n",
    "* **long** - Longitude coordinate\n",
    "* **sqft_living15** - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "* **sqft_lot15** - The square footage of the land lots of the nearest 15 neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Condition Explaination\n",
    "https://info.kingcounty.gov/assessor/esales/Glossary.aspx?type=r#d (accessed 12/6/2021)\n",
    "\n",
    "Relative to age and grade. Coded 1-5.\n",
    "\n",
    "1 = Poor- Worn out. Repair and overhaul needed on painted surfaces, roofing, plumbing, heating and numerous functional inadequacies. Excessive deferred maintenance and abuse, limited value-in-use, approaching abandonment or major reconstruction; reuse or change in occupancy is imminent. Effective age is near the end of the scale regardless of the actual chronological age.\n",
    "\n",
    "2 = Fair- Badly worn. Much repair needed. Many items need refinishing or overhauling, deferred maintenance obvious, inadequate building utility and systems all shortening the life expectancy and increasing the effective age.\n",
    "\n",
    "3 = Average- Some evidence of deferred maintenance and normal obsolescence with age in that a few minor repairs are needed, along with some refinishing. All major components still functional and contributing toward an extended life expectancy. Effective age and utility is standard for like properties of its class and usage.\n",
    "\n",
    "4 = Good- No obvious maintenance required but neither is everything new. Appearance and utility are above the standard and the overall effective age will be lower than the typical property.\n",
    "\n",
    "5= Very Good- All items well maintained, many having been overhauled and repaired as they have shown signs of wear, increasing the life expectancy and lowering the effective age with little deterioration or obsolescence evident with a high degree of utility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Grade Explaination\n",
    "https://info.kingcounty.gov/assessor/esales/Glossary.aspx?type=r#d (accessed 12/6/2021)\n",
    "\n",
    "\n",
    "Represents the construction quality of improvements. Grades run from grade 1 to 13. Generally defined as:\n",
    "\n",
    "1-3 Falls short of minimum building standards. Normally cabin or inferior structure.\n",
    "\n",
    "4 Generally older, low quality construction. Does not meet code.\n",
    "\n",
    "5 Low construction costs and workmanship. Small, simple design.\n",
    "\n",
    "6 Lowest grade currently meeting building code. Low quality materials and simple designs.\n",
    "\n",
    "7 Average grade of construction and design. Commonly seen in plats and older sub-divisions.\n",
    "\n",
    "8 Just above average in construction and design. Usually better materials in both the exterior and interior finish work.\n",
    "\n",
    "9 Better architectural design with extra interior and exterior design and quality.\n",
    "\n",
    "10 Homes of this quality generally have high quality features. Finish work is better and more design quality is seen in the floor plans. Generally have a larger square footage.\n",
    "\n",
    "11 Custom design and higher quality finish work with added amenities of solid woods, bathroom fixtures and more luxurious options.\n",
    "\n",
    "12 Custom design and excellent builders. All materials are of the highest quality and all conveniences are present.\n",
    "\n",
    "13 Generally custom designed and built. Mansion level. Large amount of highest quality cabinet work, wood trim, marble, entry ways etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Uncessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.470148Z",
     "start_time": "2021-12-17T18:37:27.461190Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[['id', 'date', 'view', 'lat', 'long', 'yr_renovated']], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.479462Z",
     "start_time": "2021-12-17T18:37:27.471431Z"
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing sqft_basement\n",
    "- slicing out all records with a '?' and calculating the correct value using other known fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.487146Z",
     "start_time": "2021-12-17T18:37:27.480405Z"
    }
   },
   "outputs": [],
   "source": [
    "unknown_basements = df[df['sqft_basement'] == '?']\n",
    "known_basements = df[df['sqft_basement'] != '?']\n",
    "\n",
    "print('Unkown Basement:',(len(unknown_basements)))\n",
    "print('Known Basement:',(len(known_basements)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.504412Z",
     "start_time": "2021-12-17T18:37:27.488019Z"
    }
   },
   "outputs": [],
   "source": [
    "sqft_basement = unknown_basements.apply(lambda x: x['sqft_living'] - x['sqft_above'], axis=1)\n",
    "unknown_basements['sqft_basement'] = sqft_basement\n",
    "\n",
    "cleaned_df = known_basements.append(unknown_basements)\n",
    "\n",
    "#changing to float so that decminals are in the same format\n",
    "cleaned_df['sqft_basement'] = cleaned_df['sqft_basement'].astype(float)\n",
    "cleaned_df['sqft_above'] = cleaned_df['sqft_above'].astype(float)\n",
    "\n",
    "cleaned_df['sqft_basement'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Zip Code to Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.529087Z",
     "start_time": "2021-12-17T18:37:27.506252Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df['zipcode'] = df['zipcode'].astype(str)\n",
    "cleaned_df['zipcode'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Bedroom Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.546402Z",
     "start_time": "2021-12-17T18:37:27.531440Z"
    }
   },
   "outputs": [],
   "source": [
    "#dropping outliers\n",
    "cleaned_df = cleaned_df.sort_values('bedrooms', ascending=False).reset_index()\n",
    "cleaned_df = cleaned_df.drop([0,1,2])\n",
    "cleaned_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.550773Z",
     "start_time": "2021-12-17T18:37:27.548081Z"
    }
   },
   "outputs": [],
   "source": [
    "#dropping index\n",
    "cleaned_df = cleaned_df.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:27.559710Z",
     "start_time": "2021-12-17T18:37:27.551749Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data with Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:43.370622Z",
     "start_time": "2021-12-17T18:37:27.560725Z"
    }
   },
   "outputs": [],
   "source": [
    "#using scatter plot to look for linear relationships\n",
    "pd.plotting.scatter_matrix(cleaned_df, figsize = [20,20]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "At first glance, the following variables seem to have linear relationships:\n",
    "- price with bedrooms, sqft_above, & sqft_basement.\n",
    "    - price also seems to have a linear relationship with categorical variable 'grade'.\n",
    "- bedrooms with bathrooms, sqft_living, sqft_above, & sqft_basement\n",
    "- sqft_living and sqft_above have the closest linear relationship\n",
    "    - They are very similar data points. I may need to eliminate one to prevent multicolinearity.\n",
    "    \n",
    "The Following Variables seem to be categorical:\n",
    "- floors\n",
    "- waterfront\n",
    "- condition\n",
    "- zip code (not shown because I have already made it an object)\n",
    "\n",
    "Ordinal Variables:\n",
    "- bedrooms\n",
    "- bathrooms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What To Do with the Ordinal Values\n",
    "\n",
    "I am going to treat grade as a continuous variable as it has very linear relationships with many features. Including price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:43.379771Z",
     "start_time": "2021-12-17T18:37:43.373054Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Waterfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:43.385895Z",
     "start_time": "2021-12-17T18:37:43.380616Z"
    }
   },
   "outputs": [],
   "source": [
    "waterfront_cleaned = cleaned_df['waterfront'].fillna(0) \n",
    "cleaned_df['waterfront'] = waterfront_cleaned\n",
    "cleaned_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:43.429199Z",
     "start_time": "2021-12-17T18:37:43.388967Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:44.457595Z",
     "start_time": "2021-12-17T18:37:43.430690Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df.hist(figsize = (20,18));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "- Price is very skewed. I will need to fix this as it is my target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of key variables again the Target (price) using jointplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:48.979590Z",
     "start_time": "2021-12-17T18:37:44.458671Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('bedrooms','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T17:51:52.531427Z",
     "start_time": "2021-12-17T17:51:52.529996Z"
    }
   },
   "source": [
    "<u>Bedrooms</u>: While this is an ordinal variable, it behaves more like a categorical than a continuous variable. \n",
    "7 bedrooms isn't necessarily better than 2 bedrooms, it all depends on the house itself. I should\n",
    "one-hot-encode this as a categorical when I get to that step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:53.342053Z",
     "start_time": "2021-12-17T18:37:48.981422Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('bathrooms','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T17:51:56.375381Z",
     "start_time": "2021-12-17T17:51:56.374064Z"
    }
   },
   "source": [
    "<u>Bathroooms</u>: Unlike bedrooms, bathrooms behave more like a continous variable than a categorical one, so I will treat it as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:37:58.128296Z",
     "start_time": "2021-12-17T18:37:53.343149Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('sqft_living','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:00:03.858668Z",
     "start_time": "2021-12-17T18:00:03.849699Z"
    }
   },
   "source": [
    "<u>Sqft_living</u>: This seems to be a very linear relationship. This makes sense as the bigger the house it, the more likely that it will be more expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:05.613896Z",
     "start_time": "2021-12-17T18:37:58.134242Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('sqft_lot','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>sqft_lot</u>: Lot size has a slight correlation with the price of a house, but there are a lot of outliers, especially with little to no lot size. It will be hard to use this as a predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:09.505966Z",
     "start_time": "2021-12-17T18:38:05.615161Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('floors','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Floors</u>: Floors is another ordinal that behaves more like a categorical value than a continuous one and will be treated as such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:13.426553Z",
     "start_time": "2021-12-17T18:38:09.506889Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('waterfront','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>Waterfront</u>: There appears to be a slight linear relationship between price and being on the waterfront."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:17.247641Z",
     "start_time": "2021-12-17T18:38:13.427535Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('condition','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T17:52:18.601785Z",
     "start_time": "2021-12-17T17:52:18.600375Z"
    }
   },
   "source": [
    "<u>Condition</u>: If treated strictly as a continous variable,  condition doesn't have much of an affect on price. I can drop this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:21.289382Z",
     "start_time": "2021-12-17T18:38:17.253690Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('grade','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T17:52:22.445954Z",
     "start_time": "2021-12-17T17:52:22.444517Z"
    }
   },
   "source": [
    "<u>Grade</u>: Grade is a fairly linear relationship with a little noise. I should keep it as a continous variable. The relationship looks like it could be improved with some cleaning, removing outliers, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:25.522163Z",
     "start_time": "2021-12-17T18:38:21.292097Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('sqft_above','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T17:52:26.415918Z",
     "start_time": "2021-12-17T17:52:26.414583Z"
    }
   },
   "source": [
    "<u>Sqft_Above</u>: Based on their description in the glossary, this is almost exactly the same thing as sqft_living. I will almost definitely need to remove one of the two of these variables and use the other due to multicolinearity. I will determine which to use when I check for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:29.399140Z",
     "start_time": "2021-12-17T18:38:25.523364Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('sqft_basement','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T17:52:30.218075Z",
     "start_time": "2021-12-17T17:52:30.216517Z"
    }
   },
   "source": [
    "<u>Sqft Basement</u>: Basement size has a slight linear relationship with price. But I also see that there are many outliers that have very little size that are skewing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:33.355531Z",
     "start_time": "2021-12-17T18:38:29.400049Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('yr_built','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T17:52:34.039331Z",
     "start_time": "2021-12-17T17:52:34.037907Z"
    }
   },
   "source": [
    "<u>Year Built</u>: Appears to have no relationship with Price and can likely be excluded from analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:37.316026Z",
     "start_time": "2021-12-17T18:38:33.356505Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('sqft_living15','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T17:52:37.943315Z",
     "start_time": "2021-12-17T17:52:37.941963Z"
    }
   },
   "source": [
    "<u>sqft_living15</u>: The size of houses nearby does have a linear relationship with price. Looks fairly close to sqft_living and sqft_above so there's a strong chance of multicolinearity here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:43.044993Z",
     "start_time": "2021-12-17T18:38:37.316990Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.jointplot('sqft_lot15','price', data=cleaned_df, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>sqft_lot15</u>: Looks identical to sqft_lot, which I likely won't end up using. This will likely be dropped as well. If I use either, it would be just that one as they are very likely to be multicolinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:43.053366Z",
     "start_time": "2021-12-17T18:38:43.045961Z"
    }
   },
   "outputs": [],
   "source": [
    "#lets go ahead and remove the features that aren't useful, per my analysis of the jointplots.\n",
    "cleaned_df = cleaned_df.drop(['sqft_lot', 'yr_built', 'sqft_lot15', 'condition'], axis=1)\n",
    "cleaned_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:43.063956Z",
     "start_time": "2021-12-17T18:38:43.054194Z"
    }
   },
   "outputs": [],
   "source": [
    "feats = ['sqft_living', 'sqft_above', 'sqft_living15','bedrooms','bathrooms', 'grade', 'condition',\n",
    "         'sqft_basement']\n",
    "corr = cleaned_df[feats].corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:38:43.320064Z",
     "start_time": "2021-12-17T18:38:43.065405Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.heatmap(corr, center=0, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:41:42.114302Z",
     "start_time": "2021-12-17T18:41:42.108847Z"
    }
   },
   "outputs": [],
   "source": [
    "list(cleaned_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:41:44.646805Z",
     "start_time": "2021-12-17T18:41:44.640895Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the problem\n",
    "outcome = 'price'\n",
    "x_cols = list(cleaned_df.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:41:47.216080Z",
     "start_time": "2021-12-17T18:41:47.201372Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(cleaned_df)\n",
    "\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:41:49.289287Z",
     "start_time": "2021-12-17T18:41:49.261934Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train), len(test))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:41:52.589596Z",
     "start_time": "2021-12-17T18:41:52.563904Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:42:08.281102Z",
     "start_time": "2021-12-17T18:42:07.977212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the actual model\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:43:25.235128Z",
     "start_time": "2021-12-17T18:43:25.198481Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract the p-value table from the summary and use it to subset our features\n",
    "summary = model.summary()\n",
    "p_table = summary.tables[1]\n",
    "p_table = pd.DataFrame(p_table.data)\n",
    "p_table.columns = p_table.iloc[0]\n",
    "p_table = p_table.drop(0)\n",
    "p_table = p_table.set_index(p_table.columns[0])\n",
    "p_table['P>|t|'] = p_table['P>|t|'].astype(float)\n",
    "x_cols = list(p_table[p_table['P>|t|'] < 0.05].index)\n",
    "x_cols.remove('Intercept')\n",
    "print(len(p_table), len(x_cols))\n",
    "print(x_cols[:5])\n",
    "p_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:35:13.254284Z",
     "start_time": "2021-12-17T18:35:13.225594Z"
    }
   },
   "outputs": [],
   "source": [
    "#removing problem zipcodes\n",
    "#df_1 = cleaned_df[cleaned_df['zipcode'] == '98002']\n",
    "#df_2 = cleaned_df[cleaned_df['zipcode'] == '98003']\n",
    "#df_3 = cleaned_df[cleaned_df['zipcode'] == '98004']\n",
    "#df_4 = cleaned_df[cleaned_df['zipcode'] == '98005']\n",
    "\n",
    "\n",
    "#print('df_1:', len(df_1))\n",
    "print('df_2:', len(df_2))\n",
    "print('df_3:', len(df_3))\n",
    "print('df_4:', len(df_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:11:04.592063Z",
     "start_time": "2021-12-14T16:11:04.569050Z"
    }
   },
   "source": [
    "Removing the problem zipcodes removes 4% of the data from the data set.\n",
    "- 964 records removed from 21,596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:35:17.839106Z",
     "start_time": "2021-12-17T18:35:17.600354Z"
    }
   },
   "outputs": [],
   "source": [
    "#problem_zips = pd.concat([df_1, df_2, df_3, df_4])\n",
    "#problem_zips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:35:26.427091Z",
     "start_time": "2021-12-17T18:35:26.408460Z"
    }
   },
   "outputs": [],
   "source": [
    "#cleaned_df['zipcode'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:36:07.177133Z",
     "start_time": "2021-12-17T18:36:07.159639Z"
    }
   },
   "outputs": [],
   "source": [
    "#cleaned_df= cleaned_df.drop(problem_zips.index)\n",
    "#cleaned_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:36:34.334016Z",
     "start_time": "2021-12-17T18:36:34.328462Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the problem\n",
    "#outcome = 'price'\n",
    "#x_cols = list(cleaned_df.columns)\n",
    "#x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:36:38.019135Z",
     "start_time": "2021-12-17T18:36:38.004207Z"
    }
   },
   "outputs": [],
   "source": [
    "#train, test = train_test_split(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:36:40.839056Z",
     "start_time": "2021-12-17T18:36:40.816058Z"
    }
   },
   "outputs": [],
   "source": [
    "#print(len(train), len(test))\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:36:46.050790Z",
     "start_time": "2021-12-17T18:36:45.625725Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the actual model\n",
    "#predictors = '+'.join(x_cols)\n",
    "#formula = outcome + '~' + predictors\n",
    "#model = ols(formula=formula, data=train).fit()\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning & Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:44:40.914698Z",
     "start_time": "2021-12-17T18:44:40.911608Z"
    }
   },
   "outputs": [],
   "source": [
    "#dropping sqft_lot15 because of it's p-value\n",
    "#encoded_df = cleaned_df_2.drop(cleaned_df_2[['sqft_lot15']], axis=1)\n",
    "#encoded_df.head(1)\n",
    "encoded_df= cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:44:13.999703Z",
     "start_time": "2021-12-17T18:44:13.991286Z"
    }
   },
   "outputs": [],
   "source": [
    "subs = [(' ', '_'),('.',''),(\"'\",\"\"),('™', ''), ('®',''),\n",
    "        ('+','plus'), ('½','half'), ('-','_')\n",
    "       ]\n",
    "def col_formatting(col):\n",
    "    for old, new in subs:\n",
    "        col = col.replace(old,new)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:44:45.132313Z",
     "start_time": "2021-12-17T18:44:45.126184Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.columns = [col_formatting(col) for col in encoded_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:44:47.614106Z",
     "start_time": "2021-12-17T18:44:47.607721Z"
    }
   },
   "outputs": [],
   "source": [
    "list(encoded_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:45:19.857677Z",
     "start_time": "2021-12-17T18:45:19.760119Z"
    }
   },
   "outputs": [],
   "source": [
    "#one-hot encoding\n",
    "feats = ['bedrooms','floors', 'waterfront', 'condition','zipcode']\n",
    "#feats = ['floors', 'waterfront','zipcode'] #treating bedrooms as a continous variable helps the model\n",
    "#feats = ['zipcode']\n",
    "encoded_df[feats] = encoded_df[feats].astype(str)\n",
    "encoded_df = pd.get_dummies(encoded_df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:37:09.322861Z",
     "start_time": "2021-12-16T20:37:09.321250Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoded_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:45:23.296958Z",
     "start_time": "2021-12-17T18:45:23.289794Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.columns = [col_formatting(col) for col in encoded_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:45:25.474011Z",
     "start_time": "2021-12-17T18:45:25.461258Z"
    }
   },
   "outputs": [],
   "source": [
    "list(encoded_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:46:02.965541Z",
     "start_time": "2021-12-17T18:46:02.959719Z"
    }
   },
   "outputs": [],
   "source": [
    "def norm_feat(series):\n",
    "    return (series - series.mean())/series.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:46:05.442757Z",
     "start_time": "2021-12-17T18:46:05.376745Z"
    }
   },
   "outputs": [],
   "source": [
    "df_norm = norm_feat(encoded_df)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Multicolinearity with VIF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:46:14.410453Z",
     "start_time": "2021-12-17T18:46:14.405066Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = list(df_norm.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:47:17.796639Z",
     "start_time": "2021-12-17T18:46:17.108603Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_norm[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "- sqft_living, sqft_above, and sqft_basement all have infinite VIF scores.\n",
    "- Several bedroom values, and condition values also have very high VIF scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using old method to find colinear pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:50:18.925348Z",
     "start_time": "2021-12-17T18:50:18.687082Z"
    }
   },
   "outputs": [],
   "source": [
    "cc_df = df_norm.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "cc_df['pairs'] = list(zip(cc_df.level_0, cc_df.level_1))\n",
    "\n",
    "cc_df.set_index(['pairs'], inplace = True)\n",
    "\n",
    "cc_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# cc for correlation coefficient\n",
    "cc_df.columns = ['cc']\n",
    "\n",
    "cc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "cc_df[(cc_df.cc>.70) & (cc_df.cc<1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis: sqft_living, and sqft_living_15 are causing a lot of multicollinearity. Dropping it will resolve most of the issues. I will also drop grade as it is so highly correlated to sqft_above, which is going to be one of my most important predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:54:14.686718Z",
     "start_time": "2021-12-17T18:54:14.656828Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_norm = df_norm.drop(['sqft_living', 'grade', 'sqft_living15'], axis=1)\n",
    "df_norm = df_norm.drop(['grade'], axis=1)\n",
    "df_norm.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T18:54:18.316743Z",
     "start_time": "2021-12-17T18:54:18.092140Z"
    }
   },
   "outputs": [],
   "source": [
    "cc_df = df_norm.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "cc_df['pairs'] = list(zip(cc_df.level_0, cc_df.level_1))\n",
    "\n",
    "cc_df.set_index(['pairs'], inplace = True)\n",
    "\n",
    "cc_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# cc for correlation coefficient\n",
    "cc_df.columns = ['cc']\n",
    "\n",
    "cc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "cc_df[(cc_df.cc>.70) & (cc_df.cc<1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condition_3 and Condition_4 mean 'average' and 'good' according to the glossary. Maybe merging them as a common value would be a good idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T19:03:00.673701Z",
     "start_time": "2021-12-17T19:03:00.651530Z"
    }
   },
   "outputs": [],
   "source": [
    "good = cleaned_df[cleaned_df['condition'] == '3']\n",
    "good = cleaned_df[cleaned_df['condition'] == '4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-17T19:03:06.604656Z",
     "start_time": "2021-12-17T19:03:06.572810Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took care of the correlated pairs. Now let's check the vif scores again and see if it resolved the infinite correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:37:49.718673Z",
     "start_time": "2021-12-16T20:37:49.716809Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = list(df_norm.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:38:26.438667Z",
     "start_time": "2021-12-16T20:37:49.719798Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_norm[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am happy with these VIF scores. There is still a decent correlation between sqft_above and bathrooms, but it is within the limits that I have set, and they are two predictors that I want to keep if at all possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the model again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:38:26.441315Z",
     "start_time": "2021-12-16T20:38:26.439630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the problem\n",
    "outcome = 'price'\n",
    "x_cols = list(df_norm.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:38:26.447960Z",
     "start_time": "2021-12-16T20:38:26.442190Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:38:26.459972Z",
     "start_time": "2021-12-16T20:38:26.449061Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train), len(test))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:38:26.472532Z",
     "start_time": "2021-12-16T20:38:26.461009Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:38:26.741574Z",
     "start_time": "2021-12-16T20:38:26.474060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the actual model\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Analysis: \n",
    "- R2 is 78.5%. I would ideally like to see it at 80% or above, but this is very close.\n",
    "- Prob(F-statistic) is 0, which means that there is good model integrity.\n",
    "- Kurtosis is still really high. I will need to refine it so that it is closer to normal (3)\n",
    "- Model is skewed. Still need to fix that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:38:26.818804Z",
     "start_time": "2021-12-16T20:38:26.742697Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more errors as price increases. This needs to be refined so that the model is accurate. This model cannot be used without further refinement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Homoscedasticity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:38:27.007077Z",
     "start_time": "2021-12-16T20:38:26.819901Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(model.predict(train[x_cols]), model.resid)\n",
    "plt.plot(model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funnel-shaped. Need to correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to switch back to encoded_df so that I can see what the acutal price is, instead of the normalized price. I will drop the same columns that I dropped from df_norm so that they contain the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:58:44.253084Z",
     "start_time": "2021-12-16T20:58:44.219162Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_df = encoded_df.drop(['sqft_living', 'grade', 'sqft_living15'], axis=1)\n",
    "#encoded_df = encoded_df.drop(['sqft_living', 'grade'], axis=1)\n",
    "encoded_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:59:03.124842Z",
     "start_time": "2021-12-16T20:59:03.010623Z"
    }
   },
   "outputs": [],
   "source": [
    "encoded_df.price.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:59:11.157801Z",
     "start_time": "2021-12-16T20:59:11.144925Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(80,100):\n",
    "    q = i/100\n",
    "    print(\"{} percentile: {}\".format(q, encoded_df.price.quantile(q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:59:19.185687Z",
     "start_time": "2021-12-16T20:59:19.171891Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,20):\n",
    "    q = i/100\n",
    "    print(\"{} percentile: {}\".format(q, encoded_df.price.quantile(q=q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:59:33.530933Z",
     "start_time": "2021-12-16T20:59:33.216877Z"
    }
   },
   "outputs": [],
   "source": [
    "df = encoded_df\n",
    "\n",
    "orig_tot = len(df)\n",
    "df = df[df.price < 1500000]# Subsetting to remove extreme outliers\n",
    "df = df[df.price > 149000]\n",
    "print('Percent removed:', (orig_tot -len(df))/orig_tot)\n",
    "df.price = df.price.map(np.log) # Applying a log transformation\n",
    "train, test = train_test_split(df)\n",
    "\n",
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "final_model = ols(formula=formula, data=train).fit()\n",
    "final_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Analysis: Removing some of the price outliers on each end improved the model. (R2 is now at 83%)\n",
    "- This only removed 2.7% of the data, which is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:00:53.630468Z",
     "start_time": "2021-12-16T21:00:53.602755Z"
    }
   },
   "outputs": [],
   "source": [
    "#making sure the changes are saved as final_df\n",
    "final_df = df\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:01:08.784329Z",
     "start_time": "2021-12-16T21:01:08.686572Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df.price.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This histogram now looks to have a normal distribution. This is a good sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing final_df and running model on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:02:12.642858Z",
     "start_time": "2021-12-16T21:02:12.524830Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:02:35.146041Z",
     "start_time": "2021-12-16T21:02:35.086081Z"
    }
   },
   "outputs": [],
   "source": [
    "final_df_norm = norm_feat(final_df)\n",
    "final_df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:04:21.642508Z",
     "start_time": "2021-12-16T21:04:21.637035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the problem\n",
    "outcome = 'price'\n",
    "x_cols = list(final_df_norm.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:04:58.223446Z",
     "start_time": "2021-12-16T21:04:58.201404Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(final_df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:05:21.350519Z",
     "start_time": "2021-12-16T21:05:21.321626Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train), len(test))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:06:05.924630Z",
     "start_time": "2021-12-16T21:06:05.896180Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:06:49.519167Z",
     "start_time": "2021-12-16T21:06:49.239003Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting the actual model\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model = ols(formula=formula, data=train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Assumptions Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:07:42.916764Z",
     "start_time": "2021-12-16T21:07:42.815212Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normality is definitely improved, but isn't where it should be yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:07:51.687357Z",
     "start_time": "2021-12-16T21:07:51.499931Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(model.predict(train[x_cols]), model.resid)\n",
    "plt.plot(model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homoscedasity: Also improved, but still not fully looking like it needs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I attempt to remove more outliers from price, the model R2 score drops, and there is no difference with the assumption checks. I will need to refine other variables to improve my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T20:30:51.087912Z",
     "start_time": "2021-12-16T20:30:51.083408Z"
    }
   },
   "source": [
    "## Checking Mulitcolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:08:45.780538Z",
     "start_time": "2021-12-16T21:08:09.895639Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = list(final_df_norm.columns)\n",
    "x_cols.remove(outcome)\n",
    "\n",
    "X = final_df_norm[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternative Approach: Building from the Ground Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:10:43.673697Z",
     "start_time": "2021-12-16T21:10:43.646887Z"
    }
   },
   "outputs": [],
   "source": [
    "alt_df = encoded_df[['price', 'sqft_above', 'bedrooms', 'bathrooms', 'sqft_basement']]\n",
    "alt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:10:52.213064Z",
     "start_time": "2021-12-16T21:10:52.211579Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = ['price', 'sqft_above', 'bedrooms', 'bathrooms', 'sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:11:00.643098Z",
     "start_time": "2021-12-16T21:11:00.639913Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(alt_df)\n",
    "\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:11:12.791483Z",
     "start_time": "2021-12-16T21:11:12.743144Z"
    }
   },
   "outputs": [],
   "source": [
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "alt_model = ols(formula=formula, data=train).fit()\n",
    "alt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:11:21.125247Z",
     "start_time": "2021-12-16T21:11:21.123776Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = list(alt_df.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:11:29.488096Z",
     "start_time": "2021-12-16T21:11:29.418759Z"
    }
   },
   "outputs": [],
   "source": [
    "X = alt_df[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:12:29.641719Z",
     "start_time": "2021-12-16T21:12:29.634645Z"
    }
   },
   "outputs": [],
   "source": [
    "alt_df = alt_df.drop(['bathrooms'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:13:03.844298Z",
     "start_time": "2021-12-16T21:13:03.839146Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = ['price', 'sqft_above', 'bedrooms', 'sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:13:18.608326Z",
     "start_time": "2021-12-16T21:13:18.603865Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = list(alt_df.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T21:13:27.068503Z",
     "start_time": "2021-12-16T21:13:27.031747Z"
    }
   },
   "outputs": [],
   "source": [
    "X = alt_df[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:30:19.365874Z",
     "start_time": "2021-12-16T16:30:19.298812Z"
    }
   },
   "outputs": [],
   "source": [
    "fig = sm.graphics.qqplot(alt_model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:30:28.072834Z",
     "start_time": "2021-12-16T16:30:28.036217Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(alt_model.predict(train[x_cols]), alt_model.resid)\n",
    "plt.plot(alt_model.predict(train[x_cols]), [0 for i in range(len(train))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe I should drop bedrooms. They can be covered in my outcome as just \"extra square feet added to the house\". A bathroom is a more unique feature that I would like to capture.\n",
    "- The normality assumption looks great now, but the model is still not homoscedastic.\n",
    "- Let me check multicolinear pairs before dropping anything..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalizing and re-running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:30:46.007673Z",
     "start_time": "2021-12-16T16:30:45.983289Z"
    }
   },
   "outputs": [],
   "source": [
    "alt_df_norm = norm_feat(alt_df)\n",
    "alt_df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:30:52.403673Z",
     "start_time": "2021-12-16T16:30:52.381255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Refit model with subset features\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + \"~\" + predictors\n",
    "alt_model = ols(formula=formula, data=train).fit()\n",
    "alt_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:19:17.676991Z",
     "start_time": "2021-12-16T16:19:17.651257Z"
    }
   },
   "outputs": [],
   "source": [
    "cc_df = alt_df.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "cc_df['pairs'] = list(zip(cc_df.level_0, cc_df.level_1))\n",
    "\n",
    "cc_df.set_index(['pairs'], inplace = True)\n",
    "\n",
    "cc_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# cc for correlation coefficient\n",
    "cc_df.columns = ['cc']\n",
    "\n",
    "cc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "cc_df[(cc_df.cc>.5) & (cc_df.cc<1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that bathrooms are the bigger problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:21:12.775504Z",
     "start_time": "2021-12-16T16:21:12.766095Z"
    }
   },
   "outputs": [],
   "source": [
    "#removing bathrooms to see what happens.\n",
    "alt_df = alt_df.drop(['bathrooms'], axis=1)\n",
    "alt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:21:33.601125Z",
     "start_time": "2021-12-16T16:21:33.599329Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = ['sqft_above', 'bedrooms', 'sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:21:46.581011Z",
     "start_time": "2021-12-16T16:21:46.515643Z"
    }
   },
   "outputs": [],
   "source": [
    "#checking VIF again to see what effect removing bedrooms had.\n",
    "X = alt_df[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:22:18.336443Z",
     "start_time": "2021-12-16T16:22:18.328382Z"
    }
   },
   "outputs": [],
   "source": [
    "cc_df = alt_df.corr().abs().stack().reset_index().sort_values(0, ascending=False)\n",
    "\n",
    "cc_df['pairs'] = list(zip(cc_df.level_0, cc_df.level_1))\n",
    "\n",
    "cc_df.set_index(['pairs'], inplace = True)\n",
    "\n",
    "cc_df.drop(columns=['level_1', 'level_0'], inplace = True)\n",
    "\n",
    "# cc for correlation coefficient\n",
    "cc_df.columns = ['cc']\n",
    "\n",
    "cc_df.drop_duplicates(inplace=True)\n",
    "\n",
    "cc_df[(cc_df.cc>.6) & (cc_df.cc<1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:20:54.364075Z",
     "start_time": "2021-12-16T16:20:54.344735Z"
    }
   },
   "outputs": [],
   "source": [
    "#removing bedrooms to see what happens.\n",
    "alt_df = alt_df.drop(['bedrooms'], axis=1)\n",
    "alt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:16:32.701461Z",
     "start_time": "2021-12-16T16:16:32.699790Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = ['sqft_above', 'bathrooms', 'sqft_basement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:17:10.033988Z",
     "start_time": "2021-12-16T16:17:09.966921Z"
    }
   },
   "outputs": [],
   "source": [
    "#checking VIF again to see what effect removing bedrooms had.\n",
    "X = alt_df[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That didn't make much of a difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking what I learned back to the old model\n",
    "- I am going to try dropping bathrooms and/or bedrooms from the old model to see if it fixes some of my issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:31:30.276513Z",
     "start_time": "2021-12-16T16:31:30.247231Z"
    }
   },
   "outputs": [],
   "source": [
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:32:30.642578Z",
     "start_time": "2021-12-16T16:32:30.627246Z"
    }
   },
   "outputs": [],
   "source": [
    "df_norm = df_norm.drop(['bathrooms'], axis=1)\n",
    "df_norm.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:33:31.797140Z",
     "start_time": "2021-12-16T16:33:31.773760Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:33:57.727169Z",
     "start_time": "2021-12-16T16:33:57.697519Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(train), len(test))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:35:27.613475Z",
     "start_time": "2021-12-16T16:35:27.609610Z"
    }
   },
   "outputs": [],
   "source": [
    "x_cols = list(df_norm.columns)\n",
    "x_cols.remove(outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:36:32.891559Z",
     "start_time": "2021-12-16T16:36:32.844602Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_norm[x_cols]\n",
    "vif = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "list(zip(x_cols, vif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-16T16:35:34.140409Z",
     "start_time": "2021-12-16T16:35:34.138472Z"
    }
   },
   "outputs": [],
   "source": [
    "vif_scores = list(zip(x_cols, vif))\n",
    "x_cols = [x for x,vif in vif_scores if vif < 5]\n",
    "print(len(vif_scores), len(x_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "641px",
    "left": "231px",
    "top": "488.125px",
    "width": "212px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "735.844px",
    "left": "729px",
    "right": "20px",
    "top": "66px",
    "width": "681px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
